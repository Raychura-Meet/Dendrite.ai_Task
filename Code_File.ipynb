{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f16d46c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 7.500000000000044e-05\n",
      "R^2 Score: 0.9998820115716058\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load JSON file with error handling\n",
    "try:\n",
    "    with open('algoparams_from_ui.json') as f:\n",
    "        params = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\"The JSON file was not found.\")\n",
    "except json.JSONDecodeError:\n",
    "    raise ValueError(\"Error decoding JSON file. Please check the file format.\")\n",
    "\n",
    "# Load CSV file with error handling\n",
    "try:\n",
    "    data = pd.read_csv('iris.csv')\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\"The CSV file was not found.\")\n",
    "except pd.errors.ParserError:\n",
    "    raise ValueError(\"Error parsing CSV file. Please check the file format.\")\n",
    "\n",
    "# Validate the JSON structure\n",
    "required_keys = ['design_state_data']\n",
    "if not all(key in params for key in required_keys):\n",
    "    raise KeyError(\"Missing required keys in JSON.\")\n",
    "\n",
    "design_data = params['design_state_data']\n",
    "\n",
    "# Validate target and prediction type\n",
    "if 'target' not in design_data or 'prediction_type' not in design_data['target']:\n",
    "    raise KeyError(\"Missing target or prediction type information in JSON.\")\n",
    "\n",
    "target = design_data['target']['target']\n",
    "prediction_type = design_data['target']['prediction_type']\n",
    "\n",
    "# Validate features\n",
    "if 'feature_handling' not in design_data:\n",
    "    raise KeyError(\"Missing feature handling information in JSON.\")\n",
    "\n",
    "features = [\n",
    "    feature for feature in design_data['feature_handling'].keys()\n",
    "    if design_data['feature_handling'][feature]['is_selected']\n",
    "]\n",
    "\n",
    "if not features:\n",
    "    raise ValueError(\"No features selected. Please select at least one feature.\")\n",
    "\n",
    "# Prepare the data\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "# Encode the target variable if it's categorical\n",
    "if y.dtype == 'object':\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "\n",
    "# Identify categorical and numerical features\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Impute missing values with validation\n",
    "imputer_strategies = {}\n",
    "for feature in features:\n",
    "    if feature in design_data['feature_handling']:\n",
    "        feature_details = design_data['feature_handling'][feature]['feature_details']\n",
    "        if 'missing_values' in feature_details and feature_details['missing_values'] == 'Impute':\n",
    "            strategy = 'mean' if feature_details['impute_with'] == 'Average of values' else 'constant'\n",
    "            fill_value = feature_details.get('impute_value', 0)\n",
    "            imputer_strategies[feature] = (strategy, fill_value)\n",
    "\n",
    "# Transformers for the pipeline\n",
    "transformers = []\n",
    "\n",
    "for feature in numerical_features:\n",
    "    if feature in imputer_strategies:\n",
    "        strategy, fill_value = imputer_strategies[feature]\n",
    "        if strategy == 'mean':\n",
    "            transformers.append((feature, SimpleImputer(strategy='mean'), [feature]))\n",
    "        else:\n",
    "            transformers.append((feature, SimpleImputer(strategy='constant', fill_value=fill_value), [feature]))\n",
    "    else:\n",
    "        transformers.append((feature, SimpleImputer(strategy='mean'), [feature]))\n",
    "\n",
    "for feature in categorical_features:\n",
    "    transformers.append((feature, OneHotEncoder(handle_unknown='ignore'), [feature]))\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers, remainder='passthrough')\n",
    "\n",
    "# Feature reduction with validation\n",
    "if 'feature_reduction' not in design_data:\n",
    "    raise KeyError(\"Missing feature reduction information in JSON.\")\n",
    "\n",
    "feature_reduction_method = design_data['feature_reduction'].get('feature_reduction_method', 'No Reduction')\n",
    "\n",
    "if feature_reduction_method == 'PCA':\n",
    "    n_components = int(design_data['feature_reduction'].get('num_of_features_to_keep', 2))\n",
    "    feature_reduction = PCA(n_components=n_components)\n",
    "elif feature_reduction_method == 'Tree-based':\n",
    "    tree_model = DecisionTreeRegressor(max_depth=5)\n",
    "    feature_reduction = SelectFromModel(tree_model)\n",
    "elif feature_reduction_method == 'Corr with Target':\n",
    "    corr_threshold = float(design_data['feature_reduction'].get('correlation_threshold', 0.1))\n",
    "    corrs = X.corrwith(pd.Series(y))\n",
    "    selected_features = corrs[abs(corrs) > corr_threshold].index.tolist()\n",
    "    feature_reduction = ColumnTransformer([(col, 'passthrough', [col]) for col in selected_features], remainder='drop')\n",
    "else:  # No Reduction\n",
    "    feature_reduction = 'passthrough'\n",
    "\n",
    "# Model selection with validation\n",
    "if prediction_type == 'Regression':\n",
    "    if 'algorithms' not in design_data:\n",
    "        raise KeyError(\"Missing algorithms information in JSON.\")\n",
    "    if design_data['algorithms']['RandomForestRegressor']['is_selected']:\n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators=design_data['algorithms']['RandomForestRegressor'].get('max_trees', 100),\n",
    "            max_depth=design_data['algorithms']['RandomForestRegressor'].get('max_depth', None)\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"No valid regression algorithm selected.\")\n",
    "else:\n",
    "    raise ValueError(\"Unsupported prediction type. Only 'Regression' is supported.\")\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_reduction', feature_reduction),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Hyperparameter tuning with GridSearchCV\n",
    "param_grid = {\n",
    "    'model__n_estimators': [10, 20, 30],\n",
    "    'model__max_depth': [10, 20, 30]\n",
    "}\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='r2')\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the model with error handling\n",
    "try:\n",
    "    grid_search.fit(X_train, y_train)\n",
    "except ValueError as e:\n",
    "    raise ValueError(f\"Error during model fitting: {e}\")\n",
    "\n",
    "# Predict\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R^2 Score: {r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81567b37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
